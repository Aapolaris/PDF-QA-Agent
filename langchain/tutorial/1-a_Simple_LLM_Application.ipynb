{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81712963",
   "metadata": {},
   "source": [
    "# LLM 调用与prompt template\n",
    "\n",
    "[build a simple LLM application with chat models and prompt template](https://python.langchain.com/docs/tutorials/llm_chain/)\n",
    "\n",
    "\n",
    "**简介**<br>\n",
    "本节主要介绍了 LLM 的导入方法以及 `PromtTemplate` 的简单使用\n",
    "\n",
    "\n",
    "**Langchain生态：**<br>\n",
    "使用 Langchain 构建的许多应用程序都包含多个步骤，并具有多个 LLM 调用的调用。随着这些应用程序变得越来越复杂，能够检查链或代理商内部到底发生了什么变得至关重要。最好的方法是与 `Langsmith` <br>\n",
    "\n",
    "**使用方法：**<br>\n",
    "- 在 LangSmith 官网注册账号，并创建一个`API KEY`\n",
    "- 配置环境变量\n",
    "\n",
    "```\n",
    "export LANGSMITH_TRACING=\"true\"\n",
    "export LANGSMITH_API_KEY=\"...\"\n",
    "export LANGSMITH_PROJECT=\"default\" # or any other project name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4322f4",
   "metadata": {},
   "source": [
    "### 1. 模型导入\n",
    "\n",
    "这里使用的是gemini，需要自行在google ai studio中申请apikey，把它填入用户环境变量。或者直接在代码中手动设置：`os.envirn['GOOGLE_API_KEY']=\"you_apikey\"`\n",
    "\n",
    "> 如果配置完环境变量成功，但是在ide运行时失败，重启即可\n",
    "\n",
    "另外，使用过程中需开启代理，并为python配置代理。\n",
    "```\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "````\n",
    "在代理工具中设置监听端口为 `7890`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5319f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "import os\n",
    "\n",
    "# 配置代理，确保代理工具监听的是7890端口\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "\n",
    "if os.environ.get(\"GOOGLE_API_KEY\"): # 自行申请并配置环境变量\n",
    "    print(\"yes\")\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash-lite\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99686845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}, id='run--0cf825bd-4d61-4fe8-bcde-dda614158d5c-0', usage_metadata={'input_tokens': 10, 'output_tokens': 2, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from english to chinese\"),\n",
    "    HumanMessage(content=\"Hi!\")\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a408a3f1",
   "metadata": {},
   "source": [
    "### 2. prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aba87ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10fc2941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Chinese', additional_kwargs={}, response_metadata={}), HumanMessage(content='how are you?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Chinese\", \"text\": \"how are you?\"})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1740e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Chinese', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='how are you?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feed80f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好吗？ (Nǐ hǎo ma?)\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
